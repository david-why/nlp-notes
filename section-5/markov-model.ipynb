{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Markov Model: Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import typing as t\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGAR_ALLAN_POE = 'https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt'\n",
    "ROBERT_FROST = 'https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['lo death hath reard himself a throne',\n",
       "  'in a strange city all alone',\n",
       "  'far down within the dim west',\n",
       "  'where the good and the bad and the worst and the best',\n",
       "  'have gone to their eternal rest'],\n",
       " ['two roads diverged in a yellow wood',\n",
       "  'and sorry i could not travel both',\n",
       "  'and be one traveler long i stood',\n",
       "  'and looked down one as far as i could',\n",
       "  'to where it bent in the undergrowth '])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eap = list(filter(None, requests.get(EDGAR_ALLAN_POE).text.splitlines()))\n",
    "# rf = list(filter(None, requests.get(ROBERT_FROST).text.splitlines()))\n",
    "\n",
    "eap_input = []\n",
    "rf_input = []\n",
    "for line in filter(str.strip, open('files/edgar_allan_poe.txt').read().splitlines()):\n",
    "    eap_input.append(line.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "for line in filter(str.strip, open('files/robert_frost.txt').read().splitlines()):\n",
    "    rf_input.append(line.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "eap_input[:5], rf_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i replied  this is nothing but dreaming',\n",
       "  'at sight of thee and thine at once awake',\n",
       "  'lying down to die have suddenly arisen',\n",
       "  'was it not fate that on this july midnight ',\n",
       "  'in the fever of a minute'],\n",
       " ['the cellar windows were banked up with sawdust',\n",
       "  'but you see dont you we take care of him ',\n",
       "  'yes but he should have married her ',\n",
       "  'except always johnjoe',\n",
       "  'come out here if you want to hear me talk '])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eap_train, eap_test = train_test_split(eap_input, random_state=1234)\n",
    "rf_train, rf_test = train_test_split(rf_input, random_state=1234)\n",
    "eap_train[:5], rf_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3331269349845201, 0.6668730650154798)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train = len(eap_train) + len(rf_train)\n",
    "eap_prior = len(eap_train) / total_train\n",
    "rf_prior = len(rf_train) / total_train\n",
    "eap_prior, rf_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovModel:\n",
    "    def __init__(self):\n",
    "        self.A: 'np.ndarray[t.Any, np.dtype[np.ndarray[t.Any, np.float64]]]' = None\n",
    "        self.pi: 'np.ndarray[t.Any, np.float64]' = None\n",
    "        self.vocab: defaultdict[str, int] = defaultdict(lambda: len(self.vocab))\n",
    "        self.reverse: t.Dict[int, str] = {}\n",
    "\n",
    "    def train(self, documents: t.List[str]) -> 'MarkovModel':\n",
    "        \"\"\"\n",
    "        Train the Markov model with the documents.\n",
    "        :param documents: The documents to learn the A and pi matrices from.\n",
    "        :returns: self\n",
    "        \"\"\"\n",
    "        self.vocab.clear()\n",
    "        self.reverse.clear()\n",
    "        for document in documents:\n",
    "            for token in filter(None, document.split()):\n",
    "                self.reverse[self.vocab[token]] = token\n",
    "        M = len(self.vocab) + 1\n",
    "        self.A = np.zeros((M, M), np.float64)\n",
    "        self.pi = np.zeros((M,), np.float64)\n",
    "        count = 0\n",
    "        for document in documents:\n",
    "            generator = filter(None, document.split())\n",
    "            first = next(generator)\n",
    "            last = self.vocab[first]\n",
    "            self.pi[last] += 1\n",
    "            for token in generator:\n",
    "                idx = self.vocab[token]\n",
    "                self.A[last][idx] += 1\n",
    "                count += 1\n",
    "                last = idx\n",
    "        self.A = np.log((self.A + 1) / (np.array([np.sum(self.A, axis=1)]).T + M))\n",
    "        # self.A = np.log(self.A)\n",
    "        self.pi = np.log((self.pi + 1) / (len(documents) + M))\n",
    "        # self.pi = np.log(self.pi)\n",
    "        return self\n",
    "\n",
    "    def probability(self, document: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the relative probability of document existing.\n",
    "        :param document: The document to calculate.\n",
    "        :returns: The log probability of the document.\n",
    "        \"\"\"\n",
    "        generator = filter(None, document.split())\n",
    "        first = next(generator)\n",
    "        last = self.vocab.get(first, len(self.vocab) - 1)\n",
    "        result = self.pi[last]\n",
    "        for token in generator:\n",
    "            idx = self.vocab.get(token, len(self.vocab) - 1)\n",
    "            result += self.A[last, idx]\n",
    "            last = idx\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap = MarkovModel().train(eap_train)\n",
    "rf = MarkovModel().train(rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-42.98739406076299"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eap.probability(eap_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    if eap.probability(data) + eap_prior > rf.probability(data) + rf_prior:\n",
    "        return 'eap'\n",
    "    return 'rf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(dataset, expected):\n",
    "    count = 0\n",
    "    for data in dataset:\n",
    "        if predict(data) == expected:\n",
    "            count += 1\n",
    "    return count / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9628597957288765)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eap_train_score = run_test(eap_train, 'eap')\n",
    "rf_train_score = run_test(rf_train, 'rf')\n",
    "eap_train_score, rf_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9722222222222222, 0.2590529247910863)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eap_test_score = run_test(eap_test, 'eap')\n",
    "rf_test_score = run_test(rf_test, 'rf')\n",
    "eap_test_score, rf_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9876275975864616, 0.7346463200439242)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    eap_train_score * rf_prior + rf_train_score * eap_prior,\n",
    "    eap_test_score * rf_prior + rf_test_score * eap_prior\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
